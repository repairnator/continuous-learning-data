diff --git a/ambry-api/src/main/java/com.github.ambry/clustermap/PartitionStateChangeListener.java b/ambry-api/src/main/java/com.github.ambry/clustermap/PartitionStateChangeListener.java
index 58edb82b8..0c9adb7b7 100644
--- a/ambry-api/src/main/java/com.github.ambry/clustermap/PartitionStateChangeListener.java
+++ b/ambry-api/src/main/java/com.github.ambry/clustermap/PartitionStateChangeListener.java
@@ -41,4 +41,10 @@
    * @param partitionName of the partition.
    */
   void onPartitionBecomeStandbyFromLeader(String partitionName);
+
+  /**
+   * Action to take when partition becomes inactive from standby.
+   * @param partitionName of the partition
+   */
+  void onPartitionBecomeInactiveFromStandby(String partitionName);
 }
diff --git a/ambry-api/src/main/java/com.github.ambry/clustermap/ReplicaSyncUpManager.java b/ambry-api/src/main/java/com.github.ambry/clustermap/ReplicaSyncUpManager.java
index 71beb9c07..388da9250 100644
--- a/ambry-api/src/main/java/com.github.ambry/clustermap/ReplicaSyncUpManager.java
+++ b/ambry-api/src/main/java/com.github.ambry/clustermap/ReplicaSyncUpManager.java
@@ -29,7 +29,7 @@
   void initiateBootstrap(ReplicaId replicaId);
 
   /**
-   * Wait until bootstrap for given replica is complete.
+   * Wait until bootstrap on given replica is complete.
    * until given replica has caught up with enough peer replicas either in local DC or remote DCs
    * @param partitionName partition name of replica that in bootstrap state
    * @throws InterruptedException
@@ -37,14 +37,14 @@
   void waitBootstrapCompleted(String partitionName) throws InterruptedException;
 
   /**
-   * Update replica lag (in byte) between two replicas (source and target)
-   * @param source the replica which is catching up with target replica
-   * @param target the replica which is in leading position
+   * Update replica lag (in byte) between two replicas (local and peer replica)
+   * @param localReplica the replica that resides on current node
+   * @param peerReplica the peer replica of local one.
    * @param lagInBytes replica lag bytes
    * @return whether the lag is updated or not. If {@code false}, it means the source replica is not tracked in this service.
    *         Either the replica has caught up and removed from service or it is an existing replica that doesn't need catchup.
    */
-  boolean updateLagBetweenReplicas(ReplicaId source, ReplicaId target, long lagInBytes);
+  boolean updateLagBetweenReplicas(ReplicaId localReplica, ReplicaId peerReplica, long lagInBytes);
 
   /**
    * Whether given replica has synced up with its peers.
@@ -56,15 +56,38 @@
 
   /**
    * Bootstrap on given replica is complete.
-   * @param partitionName partition name of replica on which bootstrap completes.
+   * @param replicaId the replica which completes bootstrap.
    */
-  void onBootstrapComplete(String partitionName);
+  void onBootstrapComplete(ReplicaId replicaId);
+
+  /**
+   * Deactivation on given replica is complete.
+   * @param replicaId the replica which completes deactivation.
+   */
+  void onDeactivationComplete(ReplicaId replicaId);
 
   /**
    * When exception/error occurs during bootstrap.
-   * @param partitionName partition name of replica which encounters error.
+   * @param replicaId the replica which encounters error.
+   */
+  void onBootstrapError(ReplicaId replicaId);
+
+  /**
+   * When exception/error occurs during deactivation.
+   * @param replicaId the replica which encounters error.
    */
-  void onBootstrapError(String partitionName);
+  void onDeactivationError(ReplicaId replicaId);
 
-  // TODO introduce decommission logic in sync-up service. For example, initiateDecommission(String partitionName)
+  /**
+   * Initiate deactivation process if the replica should become INACTIVE from STANDBY on current node.
+   * @param replicaId the replica to deactivate
+   */
+  void initiateDeactivation(ReplicaId replicaId);
+
+  /**
+   * Wait until deactivation on given replica is complete.
+   * @param partitionName the name of replica that is within Standby-To-Inactive transition.
+   * @throws InterruptedException
+   */
+  void waitDeactivationCompleted(String partitionName) throws InterruptedException;
 }
diff --git a/ambry-api/src/main/java/com.github.ambry/clustermap/StateTransitionException.java b/ambry-api/src/main/java/com.github.ambry/clustermap/StateTransitionException.java
index 243654774..8d6f9157e 100644
--- a/ambry-api/src/main/java/com.github.ambry/clustermap/StateTransitionException.java
+++ b/ambry-api/src/main/java/com.github.ambry/clustermap/StateTransitionException.java
@@ -13,6 +13,9 @@
  */
 package com.github.ambry.clustermap;
 
+/**
+ * An extension of {@link RuntimeException} used to record exceptions occurred during state transition.
+ */
 public class StateTransitionException extends RuntimeException {
   private static final long serialVersionUID = 1L;
   private final TransitionErrorCode error;
@@ -26,6 +29,11 @@ public TransitionErrorCode getErrorCode() {
     return error;
   }
 
+  /**
+   * All types of error code that associate with {@link StateTransitionException}. The error code is currently used by
+   * tests to determine location of exception. In production environment, if transition exception occurs, the message
+   * together with error code should be recorded in Helix log which helps us investigate failure cause.
+   */
   public enum TransitionErrorCode {
     /**
      * If replica is not present in Helix and not found on current node.
@@ -42,6 +50,10 @@ public TransitionErrorCode getErrorCode() {
     /**
      * If bootstrap process fails at some point for specific replica.
      */
-    BootstrapFailure
+    BootstrapFailure,
+    /**
+     * If failure occurs during Standby-To-Inactive transition.
+     */
+    DeactivationFailure
   }
 }
diff --git a/ambry-api/src/main/java/com.github.ambry/replication/ReplicationAPI.java b/ambry-api/src/main/java/com.github.ambry/replication/ReplicationAPI.java
index e84378982..c2b5ffa7b 100644
--- a/ambry-api/src/main/java/com.github.ambry/replication/ReplicationAPI.java
+++ b/ambry-api/src/main/java/com.github.ambry/replication/ReplicationAPI.java
@@ -14,6 +14,7 @@
 package com.github.ambry.replication;
 
 import com.github.ambry.clustermap.PartitionId;
+import com.github.ambry.store.StoreException;
 import java.util.Collection;
 import java.util.List;
 
@@ -41,9 +42,10 @@
    * @param hostName HostName of the datanode where the replica belongs to
    * @param replicaPath Replica Path of the replica interested in
    * @param totalBytesRead Total bytes read by the replica
+   * @throws StoreException
    */
   void updateTotalBytesReadByRemoteReplica(PartitionId partitionId, String hostName, String replicaPath,
-      long totalBytesRead);
+      long totalBytesRead) throws StoreException;
 
   /**
    * Gets the replica lag of the remote replica with the local store
diff --git a/ambry-api/src/main/java/com.github.ambry/store/Store.java b/ambry-api/src/main/java/com.github.ambry/store/Store.java
index 185dce87f..065e6d96e 100644
--- a/ambry-api/src/main/java/com.github.ambry/store/Store.java
+++ b/ambry-api/src/main/java/com.github.ambry/store/Store.java
@@ -100,6 +100,12 @@
    */
   long getSizeInBytes();
 
+  /**
+   * @return absolute end position of last PUT in bytes.
+   * @throws StoreException
+   */
+  long getEndPositionOfLastPut() throws StoreException;
+
   /**
    * @return true if the store contains no data
    */
diff --git a/ambry-cloud/src/main/java/com.github.ambry.cloud/CloudBlobStore.java b/ambry-cloud/src/main/java/com.github.ambry.cloud/CloudBlobStore.java
index 085ae3188..16a155f31 100644
--- a/ambry-cloud/src/main/java/com.github.ambry.cloud/CloudBlobStore.java
+++ b/ambry-cloud/src/main/java/com.github.ambry.cloud/CloudBlobStore.java
@@ -486,6 +486,11 @@ public ReplicaState getCurrentState() {
     throw new UnsupportedOperationException("Method not supported");
   }
 
+  @Override
+  public long getEndPositionOfLastPut() throws StoreException {
+    throw new UnsupportedOperationException("Method not supported");
+  }
+
   @Override
   public void shutdown() {
     recentBlobCache.clear();
diff --git a/ambry-cloud/src/main/java/com.github.ambry.cloud/VcrReplicationManager.java b/ambry-cloud/src/main/java/com.github.ambry.cloud/VcrReplicationManager.java
index 153ce7cec..1487f73ad 100644
--- a/ambry-cloud/src/main/java/com.github.ambry.cloud/VcrReplicationManager.java
+++ b/ambry-cloud/src/main/java/com.github.ambry.cloud/VcrReplicationManager.java
@@ -60,7 +60,6 @@
   private final VirtualReplicatorCluster virtualReplicatorCluster;
   private final CloudStorageCompactor cloudStorageCompactor;
   private final Map<String, Store> partitionStoreMap = new HashMap<>();
-  private final StoreManager storeManager;
 
   public VcrReplicationManager(VerifiableProperties properties, CloudConfig cloudConfig,
       ReplicationConfig replicationConfig, ClusterMapConfig clusterMapConfig, StoreConfig storeConfig,
@@ -71,11 +70,11 @@ public VcrReplicationManager(VerifiableProperties properties, CloudConfig cloudC
       String transformerClassName) throws ReplicationException {
     super(replicationConfig, clusterMapConfig, storeKeyFactory, clusterMap, scheduler,
         virtualReplicatorCluster.getCurrentDataNodeId(), Collections.emptyList(), connectionPool,
-        vcrMetrics.getMetricRegistry(), requestNotification, storeKeyConverterFactory, transformerClassName, null);
+        vcrMetrics.getMetricRegistry(), requestNotification, storeKeyConverterFactory, transformerClassName, null,
+        storeManager);
     this.properties = properties;
     this.cloudConfig = cloudConfig;
     this.storeConfig = storeConfig;
-    this.storeManager = storeManager;
     this.virtualReplicatorCluster = virtualReplicatorCluster;
     this.vcrMetrics = vcrMetrics;
     this.cloudDestination = cloudDestination;
diff --git a/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryPartitionStateModel.java b/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryPartitionStateModel.java
index 3f3993001..441449734 100644
--- a/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryPartitionStateModel.java
+++ b/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryPartitionStateModel.java
@@ -32,16 +32,13 @@
   private final String partitionName;
   private final PartitionStateChangeListener partitionStateChangeListener;
   private final ClusterMapConfig clusterMapConfig;
-  private final ReplicaSyncUpManager replicaSyncUpManager;
 
   AmbryPartitionStateModel(String resourceName, String partitionName,
-      PartitionStateChangeListener partitionStateChangeListener, ClusterMapConfig clusterMapConfig,
-      ReplicaSyncUpManager replicaSyncUpManager) {
+      PartitionStateChangeListener partitionStateChangeListener, ClusterMapConfig clusterMapConfig) {
     this.resourceName = resourceName;
     this.partitionName = partitionName;
     this.partitionStateChangeListener = Objects.requireNonNull(partitionStateChangeListener);
     this.clusterMapConfig = Objects.requireNonNull(clusterMapConfig);
-    this.replicaSyncUpManager = Objects.requireNonNull(replicaSyncUpManager);
     StateModelParser parser = new StateModelParser();
     _currentState = parser.getInitialState(AmbryPartitionStateModel.class);
   }
@@ -63,16 +60,6 @@ public void onBecomeStandbyFromBootstrap(Message message, NotificationContext co
     if (clusterMapConfig.clustermapEnableStateModelListener) {
       partitionStateChangeListener.onPartitionBecomeStandbyFromBootstrap(partitionName);
     }
-    try {
-      replicaSyncUpManager.waitBootstrapCompleted(partitionName);
-    } catch (InterruptedException e) {
-      logger.error("Bootstrap was interrupted on partition {}", partitionName);
-      throw new StateTransitionException("Bootstrap failed or was interrupted",
-          StateTransitionException.TransitionErrorCode.BootstrapFailure);
-    } catch (StateTransitionException e) {
-      logger.error("Bootstrap didn't complete.", e);
-      throw e;
-    }
   }
 
   @Transition(to = "LEADER", from = "STANDBY")
@@ -91,8 +78,12 @@ public void onBecomeStandbyFromLeader(Message message, NotificationContext conte
 
   @Transition(to = "INACTIVE", from = "STANDBY")
   public void onBecomeInactiveFromStandby(Message message, NotificationContext context) {
-    logger.info("Partition {} in resource {} is becoming INACTIVE from STANDBY", message.getPartitionName(),
+    String partitionName = message.getPartitionName();
+    logger.info("Partition {} in resource {} is becoming INACTIVE from STANDBY", partitionName,
         message.getResourceName());
+    if (clusterMapConfig.clustermapEnableStateModelListener) {
+      partitionStateChangeListener.onPartitionBecomeInactiveFromStandby(partitionName);
+    }
   }
 
   @Transition(to = "OFFLINE", from = "INACTIVE")
diff --git a/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryReplicaSyncUpManager.java b/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryReplicaSyncUpManager.java
index b8ce1f36f..659d240f9 100644
--- a/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryReplicaSyncUpManager.java
+++ b/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryReplicaSyncUpManager.java
@@ -23,6 +23,8 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import static com.github.ambry.clustermap.StateTransitionException.TransitionErrorCode.*;
+
 
 /**
  * An implementation of {@link ReplicaSyncUpManager} that helps track replica catchup state.
@@ -31,13 +33,15 @@
  * Every time {@link ReplicaSyncUpManager#initiateBootstrap(ReplicaId)} is called, a new latch (with initial value = 1)
  * is created associated with given replica. Any caller that invokes {@link ReplicaSyncUpManager#waitBootstrapCompleted(String)}
  * is blocked and wait until corresponding latch counts to zero. External component (i.e. replication manager) is able to
- * call {@link ReplicaSyncUpManager#onBootstrapComplete(String)} or {@link ReplicaSyncUpManager#onBootstrapError(String)}
+ * call {@link ReplicaSyncUpManager#onBootstrapComplete(ReplicaId)} or {@link ReplicaSyncUpManager#onBootstrapError(ReplicaId)}
  * to mark sync-up success or failure by counting down the latch. This will unblock caller waiting fot this latch and
  * proceed with subsequent actions.
  */
 public class AmbryReplicaSyncUpManager implements ReplicaSyncUpManager {
   private final ConcurrentHashMap<String, CountDownLatch> partitionToBootstrapLatch = new ConcurrentHashMap<>();
+  private final ConcurrentHashMap<String, CountDownLatch> partitionToDeactivationLatch = new ConcurrentHashMap<>();
   private final ConcurrentHashMap<String, Boolean> partitionToBootstrapSuccess = new ConcurrentHashMap<>();
+  private final ConcurrentHashMap<String, Boolean> partitionToDeactivationSuccess = new ConcurrentHashMap<>();
   private final ConcurrentHashMap<ReplicaId, LocalReplicaLagInfos> replicaToLagInfos = new ConcurrentHashMap<>();
   private final ClusterMapConfig clusterMapConfig;
 
@@ -52,7 +56,17 @@ public void initiateBootstrap(ReplicaId replicaId) {
     partitionToBootstrapLatch.put(replicaId.getPartitionId().toPathString(), new CountDownLatch(1));
     partitionToBootstrapSuccess.put(replicaId.getPartitionId().toPathString(), false);
     replicaToLagInfos.put(replicaId,
-        new LocalReplicaLagInfos(replicaId, clusterMapConfig.clustermapReplicaCatchupAcceptableLagBytes));
+        new LocalReplicaLagInfos(replicaId, clusterMapConfig.clustermapReplicaCatchupAcceptableLagBytes,
+            ReplicaState.BOOTSTRAP));
+  }
+
+  @Override
+  public void initiateDeactivation(ReplicaId replicaId) {
+    partitionToDeactivationLatch.put(replicaId.getPartitionId().toPathString(), new CountDownLatch(1));
+    partitionToDeactivationSuccess.put(replicaId.getPartitionId().toPathString(), false);
+    // once deactivation is initiated, local replica won't receive new PUTs. All remote replicas should be able to
+    // eventually catch with last PUT in local store. Hence, we set acceptable lag threshold to 0.
+    replicaToLagInfos.put(replicaId, new LocalReplicaLagInfos(replicaId, 0, ReplicaState.INACTIVE));
   }
 
   /**
@@ -69,20 +83,38 @@ public void waitBootstrapCompleted(String partitionName) throws InterruptedExcep
       latch.await();
       partitionToBootstrapLatch.remove(partitionName);
       if (!partitionToBootstrapSuccess.remove(partitionName)) {
-        throw new StateTransitionException("Partition " + partitionName + " failed on bootstrap.",
-            StateTransitionException.TransitionErrorCode.BootstrapFailure);
+        throw new StateTransitionException("Partition " + partitionName + " failed to bootstrap.", BootstrapFailure);
       }
       logger.info("Bootstrap is complete on partition {}", partitionName);
     }
   }
 
   @Override
-  public boolean updateLagBetweenReplicas(ReplicaId source, ReplicaId target, long lagInBytes) {
+  public void waitDeactivationCompleted(String partitionName) throws InterruptedException {
+    CountDownLatch latch = partitionToDeactivationLatch.get(partitionName);
+    if (latch == null) {
+      logger.error("Partition {} is not found for deactivation", partitionName);
+      throw new StateTransitionException("No deactivation latch is found for partition " + partitionName,
+          ReplicaNotFound);
+    } else {
+      logger.info("Waiting for partition {} to be deactivated", partitionName);
+      latch.await();
+      partitionToDeactivationLatch.remove(partitionName);
+      // throw exception to put replica into ERROR stateï¼Œ this happens when disk crashes during deactivation
+      if (!partitionToDeactivationSuccess.remove(partitionName)) {
+        throw new StateTransitionException("Deactivation failed on partition " + partitionName, DeactivationFailure);
+      }
+      logger.info("Deactivation is complete on partition {}", partitionName);
+    }
+  }
+
+  @Override
+  public boolean updateLagBetweenReplicas(ReplicaId localReplica, ReplicaId peerReplica, long lagInBytes) {
     boolean updated = false;
-    if (replicaToLagInfos.containsKey(source)) {
-      replicaToLagInfos.get(source).updateLagInfo(target, lagInBytes);
+    if (replicaToLagInfos.containsKey(localReplica)) {
+      replicaToLagInfos.get(localReplica).updateLagInfo(peerReplica, lagInBytes);
       if (logger.isDebugEnabled()) {
-        logger.debug(replicaToLagInfos.get(source).toString());
+        logger.debug(replicaToLagInfos.get(localReplica).toString());
       }
       updated = true;
     }
@@ -105,9 +137,17 @@ public boolean isSyncUpComplete(ReplicaId replicaId) {
    * unblock external service waiting on this latch.
    */
   @Override
-  public void onBootstrapComplete(String partitionName) {
-    partitionToBootstrapSuccess.put(partitionName, true);
-    countDownLatch(partitionName);
+  public void onBootstrapComplete(ReplicaId replicaId) {
+    partitionToBootstrapSuccess.put(replicaId.getPartitionId().toPathString(), true);
+    replicaToLagInfos.remove(replicaId);
+    countDownLatch(partitionToBootstrapLatch, replicaId.getPartitionId().toPathString());
+  }
+
+  @Override
+  public void onDeactivationComplete(ReplicaId replicaId) {
+    partitionToDeactivationSuccess.put(replicaId.getPartitionId().toPathString(), true);
+    replicaToLagInfos.remove(replicaId);
+    countDownLatch(partitionToDeactivationLatch, replicaId.getPartitionId().toPathString());
   }
 
   /**
@@ -115,8 +155,15 @@ public void onBootstrapComplete(String partitionName) {
    * This method will count down latch and terminates bootstrap.
    */
   @Override
-  public void onBootstrapError(String partitionName) {
-    countDownLatch(partitionName);
+  public void onBootstrapError(ReplicaId replicaId) {
+    replicaToLagInfos.remove(replicaId);
+    countDownLatch(partitionToBootstrapLatch, replicaId.getPartitionId().toPathString());
+  }
+
+  @Override
+  public void onDeactivationError(ReplicaId replicaId) {
+    replicaToLagInfos.remove(replicaId);
+    countDownLatch(partitionToDeactivationLatch, replicaId.getPartitionId().toPathString());
   }
 
   /**
@@ -125,17 +172,20 @@ public void onBootstrapError(String partitionName) {
   void reset() {
     partitionToBootstrapLatch.clear();
     partitionToBootstrapSuccess.clear();
+    partitionToDeactivationLatch.clear();
+    partitionToDeactivationSuccess.clear();
     replicaToLagInfos.clear();
   }
 
   /**
    * Count down the latch associated with given partition
+   * @param countDownLatchMap the map in which the latch is specified for given partition.
    * @param partitionName the partition whose corresponding latch needs to count down.
    */
-  private void countDownLatch(String partitionName) {
-    CountDownLatch latch = partitionToBootstrapLatch.get(partitionName);
+  private void countDownLatch(Map<String, CountDownLatch> countDownLatchMap, String partitionName) {
+    CountDownLatch latch = countDownLatchMap.get(partitionName);
     if (latch == null) {
-      throw new IllegalStateException("No bootstrap latch is found for partition " + partitionName);
+      throw new IllegalStateException("No countdown latch is found for partition " + partitionName);
     } else {
       latch.countDown();
     }
@@ -156,9 +206,18 @@ private void countDownLatch(String partitionName) {
     private final long acceptableThreshold;
     private final int catchupTarget;
     private final ReplicaId replicaOnCurrentNode;
+    private final ReplicaState currentState;
 
-    LocalReplicaLagInfos(ReplicaId localReplica, long acceptableThreshold) {
+    /**
+     * Constructor for {@link LocalReplicaLagInfos}.
+     * @param localReplica {@link ReplicaId} on current node.
+     * @param acceptableThreshold acceptable threshold in byte to determine if replica has caught up (or has been caught
+     *                            up with by peer replicas)
+     * @param currentState the current {@link ReplicaState} of local replica.
+     */
+    LocalReplicaLagInfos(ReplicaId localReplica, long acceptableThreshold, ReplicaState currentState) {
       this.acceptableThreshold = acceptableThreshold;
+      this.currentState = currentState;
       Set<ReplicaId> peerReplicas = new HashSet<>();
       // new replica only needs to catch up with STANDBY or LEADER replicas
       for (ReplicaState state : EnumSet.of(ReplicaState.STANDBY, ReplicaState.LEADER)) {
@@ -167,6 +226,11 @@ private void countDownLatch(String partitionName) {
       replicaOnCurrentNode = localReplica;
       localDcName = localReplica.getDataNodeId().getDatacenterName();
       for (ReplicaId peerReplica : peerReplicas) {
+        if (peerReplica == replicaOnCurrentNode) {
+          // This may happen when local replica transits from STANDBY to INACTIVE because Helix still shows local replica
+          // is in STANDBY. We skip here if peer replica == replica on current node.
+          continue;
+        }
         // put peer replicas into local/remote DC maps (initial value is Long.MAX_VALUE)
         if (peerReplica.getDataNodeId().getDatacenterName().equals(localDcName)) {
           localDcPeerReplicaAndLag.put(peerReplica, Long.MAX_VALUE);
@@ -213,7 +277,11 @@ boolean hasSyncedUpWithEnoughPeers() {
     @Override
     public String toString() {
       StringBuilder sb = new StringBuilder();
-      sb.append("Replica(").append(replicaOnCurrentNode.getReplicaPath()).append(") lag infos: ");
+      sb.append("Replica(")
+          .append(replicaOnCurrentNode.getReplicaPath())
+          .append("), current state: ")
+          .append(currentState)
+          .append(", lag infos: ");
       sb.append("Local DC peer replicas lag: {");
       for (Map.Entry<ReplicaId, Long> replicaAndLag : localDcPeerReplicaAndLag.entrySet()) {
         sb.append(" [")
diff --git a/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryStateModelFactory.java b/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryStateModelFactory.java
index a22784118..55e17aef7 100644
--- a/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryStateModelFactory.java
+++ b/ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryStateModelFactory.java
@@ -25,13 +25,10 @@
 class AmbryStateModelFactory extends StateModelFactory<StateModel> {
   private final ClusterMapConfig clustermapConfig;
   private final PartitionStateChangeListener partitionStateChangeListener;
-  private final ReplicaSyncUpManager replicaSyncUpManager;
 
-  AmbryStateModelFactory(ClusterMapConfig clusterMapConfig, PartitionStateChangeListener partitionStateChangeListener,
-      ReplicaSyncUpManager replicaSyncUpManager) {
+  AmbryStateModelFactory(ClusterMapConfig clusterMapConfig, PartitionStateChangeListener partitionStateChangeListener) {
     this.clustermapConfig = clusterMapConfig;
     this.partitionStateChangeListener = partitionStateChangeListener;
-    this.replicaSyncUpManager = replicaSyncUpManager;
   }
 
   /**
@@ -46,8 +43,7 @@ public StateModel createNewStateModel(String resourceName, String partitionName)
     switch (clustermapConfig.clustermapStateModelDefinition) {
       case AmbryStateModelDefinition.AMBRY_LEADER_STANDBY_MODEL:
         stateModelToReturn =
-            new AmbryPartitionStateModel(resourceName, partitionName, partitionStateChangeListener, clustermapConfig,
-                replicaSyncUpManager);
+            new AmbryPartitionStateModel(resourceName, partitionName, partitionStateChangeListener, clustermapConfig);
         break;
       case LeaderStandbySMD.name:
         stateModelToReturn = new DefaultLeaderStandbyStateModel();
diff --git a/ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixParticipant.java b/ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixParticipant.java
index 9ffc8035a..696b9f1a6 100644
--- a/ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixParticipant.java
+++ b/ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixParticipant.java
@@ -39,6 +39,8 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import static com.github.ambry.clustermap.StateTransitionException.TransitionErrorCode.*;
+
 
 /**
  * An implementation of {@link ClusterParticipant} that registers as a participant to a Helix cluster.
@@ -97,7 +99,7 @@ public void participate(List<AmbryHealthReport> ambryHealthReports) throws IOExc
         clusterMapConfig.clustermapStateModelDefinition);
     StateMachineEngine stateMachineEngine = manager.getStateMachineEngine();
     stateMachineEngine.registerStateModelFactory(clusterMapConfig.clustermapStateModelDefinition,
-        new AmbryStateModelFactory(clusterMapConfig, this, replicaSyncUpManager));
+        new AmbryStateModelFactory(clusterMapConfig, this));
     registerHealthReportTasks(stateMachineEngine, ambryHealthReports);
     try {
       synchronized (helixAdministrationLock) {
@@ -316,6 +318,17 @@ public void onPartitionBecomeStandbyFromBootstrap(String partitionName) {
         partitionStateChangeListeners.get(StateModelListenerType.ReplicationManagerListener);
     if (replicationManagerListener != null) {
       replicationManagerListener.onPartitionBecomeStandbyFromBootstrap(partitionName);
+      // after bootstrap is initiated in ReplicationManager, transition is blocked here and wait until local replica has
+      // caught up with enough peer replicas.
+      try {
+        replicaSyncUpManager.waitBootstrapCompleted(partitionName);
+      } catch (InterruptedException e) {
+        logger.error("Bootstrap was interrupted on partition {}", partitionName);
+        throw new StateTransitionException("Bootstrap failed or was interrupted", BootstrapFailure);
+      } catch (StateTransitionException e) {
+        logger.error("Bootstrap didn't complete on partition {}", partitionName, e);
+        throw e;
+      }
     }
   }
 
@@ -336,4 +349,31 @@ public void onPartitionBecomeStandbyFromLeader(String partitionName) {
       cloudToStoreReplicationListener.onPartitionBecomeStandbyFromLeader(partitionName);
     }
   }
+
+  @Override
+  public void onPartitionBecomeInactiveFromStandby(String partitionName) {
+    // 1. storage manager marks store local state as INACTIVE and disables compaction on this partition
+    PartitionStateChangeListener storageManagerListener =
+        partitionStateChangeListeners.get(StateModelListenerType.StorageManagerListener);
+    if (storageManagerListener != null) {
+      storageManagerListener.onPartitionBecomeInactiveFromStandby(partitionName);
+    }
+    // 2. replication manager initiates deactivation
+    PartitionStateChangeListener replicationManagerListener =
+        partitionStateChangeListeners.get(StateModelListenerType.ReplicationManagerListener);
+    if (replicationManagerListener != null) {
+      replicationManagerListener.onPartitionBecomeInactiveFromStandby(partitionName);
+      // after deactivation is initiated in ReplicationManager, transition is blocked here and wait until enough peer
+      // replicas have caught up with last PUT in local store.
+      try {
+        replicaSyncUpManager.waitDeactivationCompleted(partitionName);
+      } catch (InterruptedException e) {
+        logger.error("Deactivation was interrupted on partition {}", partitionName);
+        throw new StateTransitionException("Deactivation failed or was interrupted", DeactivationFailure);
+      } catch (StateTransitionException e) {
+        logger.error("Deactivation didn't complete on partition {}", partitionName, e);
+        throw e;
+      }
+    }
+  }
 }
diff --git a/ambry-clustermap/src/test/java/com.github.ambry.clustermap/AmbryReplicaSyncUpManagerTest.java b/ambry-clustermap/src/test/java/com.github.ambry.clustermap/AmbryReplicaSyncUpManagerTest.java
index 312fc6360..2f112cef4 100644
--- a/ambry-clustermap/src/test/java/com.github.ambry.clustermap/AmbryReplicaSyncUpManagerTest.java
+++ b/ambry-clustermap/src/test/java/com.github.ambry.clustermap/AmbryReplicaSyncUpManagerTest.java
@@ -15,6 +15,7 @@
 
 import com.github.ambry.config.ClusterMapConfig;
 import com.github.ambry.config.VerifiableProperties;
+import com.github.ambry.utils.TestUtils;
 import com.github.ambry.utils.Utils;
 import java.io.IOException;
 import java.util.ArrayList;
@@ -26,9 +27,11 @@
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;
 import org.apache.helix.model.Message;
+import org.json.JSONObject;
 import org.junit.Test;
 import org.mockito.Mockito;
 
+import static com.github.ambry.clustermap.TestUtils.*;
 import static org.junit.Assert.*;
 import static org.mockito.Mockito.*;
 
@@ -41,13 +44,11 @@
   private AmbryPartitionStateModel stateModel;
   private AmbryReplicaSyncUpManager replicaSyncUpService;
   private ReplicaId currentReplica;
-  private MockPartitionStateChangeListener mockStateChangeListener;
+  private MockHelixParticipant mockHelixParticipant;
   private Message mockMessage;
   private final List<ReplicaId> localDcPeerReplicas;
   private final List<ReplicaId> remoteDcPeerReplicas;
   private final MockClusterMap clusterMap;
-  private CountDownLatch listenerLatch;
-  private ReplicaState replicaState = ReplicaState.OFFLINE;
 
   public AmbryReplicaSyncUpManagerTest() throws IOException {
     clusterMap = new MockClusterMap();
@@ -63,18 +64,23 @@ public AmbryReplicaSyncUpManagerTest() throws IOException {
     replicas.removeAll(localDcPeers);
     localDcPeerReplicas = new ArrayList<>(localDcPeers);
     remoteDcPeerReplicas = new ArrayList<>(replicas);
+    List<TestUtils.ZkInfo> zkInfoList = new ArrayList<>();
+    zkInfoList.add(new TestUtils.ZkInfo(null, "DC1", (byte) 0, 2199, false));
+    JSONObject zkJson = constructZkLayoutJSON(zkInfoList);
     Properties properties = new Properties();
     properties.setProperty("clustermap.cluster.name", "test");
     properties.setProperty("clustermap.datacenter.name", "DC1");
     properties.setProperty("clustermap.host.name", "localhost");
     properties.setProperty("clustermap.replica.catchup.acceptable.lag.bytes", Long.toString(100L));
     properties.setProperty("clustermap.enable.state.model.listener", Boolean.toString(true));
+    properties.setProperty("clustermap.dcs.zk.connect.strings", zkJson.toString(2));
     ClusterMapConfig clusterMapConfig = new ClusterMapConfig(new VerifiableProperties(properties));
-    replicaSyncUpService = new AmbryReplicaSyncUpManager(clusterMapConfig);
-    mockStateChangeListener = new MockPartitionStateChangeListener();
+    mockHelixParticipant = new MockHelixParticipant(clusterMapConfig);
+    replicaSyncUpService = (AmbryReplicaSyncUpManager) mockHelixParticipant.getReplicaSyncUpManager();
+    mockHelixParticipant.currentReplica = currentReplica;
+    mockHelixParticipant.replicaSyncUpService = replicaSyncUpService;
     stateModel =
-        new AmbryPartitionStateModel(RESOURCE_NAME, partition.toPathString(), mockStateChangeListener, clusterMapConfig,
-            replicaSyncUpService);
+        new AmbryPartitionStateModel(RESOURCE_NAME, partition.toPathString(), mockHelixParticipant, clusterMapConfig);
     mockMessage = Mockito.mock(Message.class);
     when(mockMessage.getPartitionName()).thenReturn(partition.toPathString());
     when(mockMessage.getResourceName()).thenReturn(RESOURCE_NAME);
@@ -89,16 +95,21 @@ public AmbryReplicaSyncUpManagerTest() throws IOException {
    * @throws Exception
    */
   @Test
-  public void basicTest() throws Exception {
+  public void bootstrapBasicTest() throws Exception {
     CountDownLatch stateModelLatch = new CountDownLatch(1);
-    listenerLatch = new CountDownLatch(1);
+    // the listener latch is to ensure state change listener in ReplicationManager or StorageManager is invoked before
+    // moving forward to rest tests.
+    mockHelixParticipant.listenerLatch = new CountDownLatch(1);
+    mockHelixParticipant.registerMockStateChangeListeners();
     // create a new thread and trigger BOOTSTRAP -> STANDBY transition
     Utils.newThread(() -> {
       stateModel.onBecomeStandbyFromBootstrap(mockMessage, null);
       stateModelLatch.countDown();
     }, false).start();
-    assertTrue("State change listener didn't get invoked within 1 sec.", listenerLatch.await(1, TimeUnit.SECONDS));
-    assertEquals("current replica should be in BOOTSTRAP state", ReplicaState.BOOTSTRAP, replicaState);
+    assertTrue("State change listener didn't get invoked within 1 sec.",
+        mockHelixParticipant.listenerLatch.await(1, TimeUnit.SECONDS));
+    assertEquals("current replica should be in BOOTSTRAP state", ReplicaState.BOOTSTRAP,
+        mockHelixParticipant.replicaState);
     assertFalse("Catchup shouldn't complete on current replica", replicaSyncUpService.isSyncUpComplete(currentReplica));
     ReplicaId localPeer1 = localDcPeerReplicas.get(0);
     ReplicaId localPeer2 = localDcPeerReplicas.get(1);
@@ -117,20 +128,55 @@ public void basicTest() throws Exception {
     replicaSyncUpService.updateLagBetweenReplicas(currentReplica, remotePeer2, 10L);
     // make current replica fall behind first peer replica in local DC again (update lag to 150 > 100)
     replicaSyncUpService.updateLagBetweenReplicas(currentReplica, localPeer1, 150L);
-    // at this time, current replica has caught up with two replicas only, so SyncUp is not complete
-    assertFalse("Catchup shouldn't complete on current replica because only one peer replica is caught up",
-        replicaSyncUpService.isSyncUpComplete(currentReplica));
-    // make current replica catch up with first peer remote dc replica
-    replicaSyncUpService.updateLagBetweenReplicas(currentReplica, remotePeer1, 10L);
-    assertTrue("Catch up should be complete on current replica because it has caught up at least 3 peer replicas",
+    // at this time, current replica has caught up with two replicas in local DC, so SyncUp is complete
+    assertTrue("Catch up should be complete on current replica because it has caught up at least 2 peer replicas",
         replicaSyncUpService.isSyncUpComplete(currentReplica));
-    replicaSyncUpService.onBootstrapComplete(currentReplica.getPartitionId().toPathString());
+    replicaSyncUpService.onBootstrapComplete(currentReplica);
     assertTrue("Bootstrap-To-Standby transition didn't complete within 1 sec.",
         stateModelLatch.await(1, TimeUnit.SECONDS));
     // reset ReplicaSyncUpManager
     replicaSyncUpService.reset();
   }
 
+  /**
+   * Basic tests for deactivation process (STANDBY -> INACTIVE transition)
+   * @throws Exception
+   */
+  @Test
+  public void deactivationBasicTest() throws Exception {
+    CountDownLatch stateModelLatch = new CountDownLatch(1);
+    // the listener latch is to ensure state change listener in ReplicationManager or StorageManager is invoked before
+    // moving forward to rest tests.
+    mockHelixParticipant.listenerLatch = new CountDownLatch(1);
+    mockHelixParticipant.registerMockStateChangeListeners();
+    // create a new thread and trigger STANDBY -> INACTIVE transition
+    Utils.newThread(() -> {
+      stateModel.onBecomeInactiveFromStandby(mockMessage, null);
+      stateModelLatch.countDown();
+    }, false).start();
+    assertTrue("State change listener didn't get invoked within 1 sec.",
+        mockHelixParticipant.listenerLatch.await(1, TimeUnit.SECONDS));
+    assertEquals("current replica should be in INACTIVE state", ReplicaState.INACTIVE,
+        mockHelixParticipant.replicaState);
+    assertFalse("Catchup shouldn't complete on current replica", replicaSyncUpService.isSyncUpComplete(currentReplica));
+    ReplicaId localPeer1 = localDcPeerReplicas.get(0);
+    ReplicaId localPeer2 = localDcPeerReplicas.get(1);
+    // make localPeer1 catch up with current replica but localPeer2 still falls behind.
+    replicaSyncUpService.updateLagBetweenReplicas(currentReplica, localPeer1, 0L);
+    replicaSyncUpService.updateLagBetweenReplicas(currentReplica, localPeer2, 5L);
+    assertFalse("Catchup shouldn't complete on current replica because only one peer replica has caught up",
+        replicaSyncUpService.isSyncUpComplete(currentReplica));
+    // make localPeer2 catch up with current replica.
+    replicaSyncUpService.updateLagBetweenReplicas(currentReplica, localPeer2, 0L);
+    assertTrue("Sync up should be complete on current replica because 2 peer replicas have caught up with it",
+        replicaSyncUpService.isSyncUpComplete(currentReplica));
+    replicaSyncUpService.onDeactivationComplete(currentReplica);
+    assertTrue("Standby-To-Inactive transition didn't complete within 1 sec.",
+        stateModelLatch.await(1, TimeUnit.SECONDS));
+    // reset ReplicaSyncUpManager
+    replicaSyncUpService.reset();
+  }
+
   /**
    * Test several failure cases where replica is not present in ReplicaSyncUpManager.
    * @throws Exception
@@ -150,7 +196,7 @@ public void replicaNotFoundFailureTest() throws Exception {
     assertFalse("Updating lag should return false because replica is not present",
         replicaSyncUpService.updateLagBetweenReplicas(replicaToTest, peerReplica, 100L));
     try {
-      replicaSyncUpService.onBootstrapError(partition.toPathString());
+      replicaSyncUpService.onBootstrapError(replicaToTest);
       fail("should fail because replica is not present");
     } catch (IllegalStateException e) {
       // expected
@@ -160,13 +206,50 @@ public void replicaNotFoundFailureTest() throws Exception {
     replicaSyncUpService.reset();
   }
 
+  /**
+   * Test failure cases during STANDBY -> INACTIVE transition
+   */
+  @Test
+  public void deactivationFailureTest() throws Exception {
+    // test replica not found exception (get another partition that is not present in ReplicaSyncUpManager)
+    PartitionId partition = clusterMap.getAllPartitionIds(null).get(1);
+    try {
+      replicaSyncUpService.waitDeactivationCompleted(partition.toPathString());
+      fail("should fail because replica is not found");
+    } catch (StateTransitionException e) {
+      assertEquals("Error code is not expected", StateTransitionException.TransitionErrorCode.ReplicaNotFound,
+          e.getErrorCode());
+    }
+    // test deactivation failure for some reason (triggered by calling onDeactivationError)
+    CountDownLatch stateModelLatch = new CountDownLatch(1);
+    mockHelixParticipant.listenerLatch = new CountDownLatch(1);
+    mockHelixParticipant.registerMockStateChangeListeners();
+    // create a new thread and trigger STANDBY -> INACTIVE transition
+    Utils.newThread(() -> {
+      try {
+        stateModel.onBecomeInactiveFromStandby(mockMessage, null);
+      } catch (StateTransitionException e) {
+        assertEquals("Error code doesn't match", StateTransitionException.TransitionErrorCode.DeactivationFailure,
+            e.getErrorCode());
+        stateModelLatch.countDown();
+      }
+    }, false).start();
+    assertTrue("State change listener didn't get invoked within 1 sec.",
+        mockHelixParticipant.listenerLatch.await(1, TimeUnit.SECONDS));
+    replicaSyncUpService.onDeactivationError(currentReplica);
+    assertTrue("Standby-To-Inactive transition didn't complete within 1 sec.",
+        stateModelLatch.await(1, TimeUnit.SECONDS));
+    replicaSyncUpService.reset();
+  }
+
   /**
    * Test BOOTSTRAP -> STANDBY transition failure
    */
   @Test
   public void bootstrapFailureTest() throws Exception {
     CountDownLatch stateModelLatch = new CountDownLatch(1);
-    listenerLatch = new CountDownLatch(1);
+    mockHelixParticipant.listenerLatch = new CountDownLatch(1);
+    mockHelixParticipant.registerMockStateChangeListeners();
     // create a new thread and trigger BOOTSTRAP -> STANDBY transition
     Utils.newThread(() -> {
       try {
@@ -177,33 +260,11 @@ public void bootstrapFailureTest() throws Exception {
         stateModelLatch.countDown();
       }
     }, false).start();
-    assertTrue("State change listener didn't get invoked within 1 sec.", listenerLatch.await(1, TimeUnit.SECONDS));
-    replicaSyncUpService.onBootstrapError(currentReplica.getPartitionId().toPathString());
+    assertTrue("State change listener didn't get invoked within 1 sec.",
+        mockHelixParticipant.listenerLatch.await(1, TimeUnit.SECONDS));
+    replicaSyncUpService.onBootstrapError(currentReplica);
     assertTrue("Bootstrap-To-Standby transition didn't complete within 1 sec.",
         stateModelLatch.await(1, TimeUnit.SECONDS));
-  }
-
-  /**
-   * Implementation of {@link PartitionStateChangeListener} to help {@link ReplicaSyncUpManager} tests
-   */
-  private class MockPartitionStateChangeListener implements PartitionStateChangeListener {
-    @Override
-    public void onPartitionBecomeBootstrapFromOffline(String partitionName) {
-    }
-
-    @Override
-    public void onPartitionBecomeStandbyFromBootstrap(String partitionName) {
-      replicaState = ReplicaState.BOOTSTRAP;
-      replicaSyncUpService.initiateBootstrap(currentReplica);
-      listenerLatch.countDown();
-    }
-
-    @Override
-    public void onPartitionBecomeLeaderFromStandby(String partitionName) {
-    }
-
-    @Override
-    public void onPartitionBecomeStandbyFromLeader(String partitionName) {
-    }
+    replicaSyncUpService.reset();
   }
 }
diff --git a/ambry-clustermap/src/test/java/com.github.ambry.clustermap/AmbryStateModelFactoryTest.java b/ambry-clustermap/src/test/java/com.github.ambry.clustermap/AmbryStateModelFactoryTest.java
index d6256d972..c9f7091dd 100644
--- a/ambry-clustermap/src/test/java/com.github.ambry.clustermap/AmbryStateModelFactoryTest.java
+++ b/ambry-clustermap/src/test/java/com.github.ambry.clustermap/AmbryStateModelFactoryTest.java
@@ -70,7 +70,12 @@ public void onPartitionBecomeLeaderFromStandby(String partitionName) {
       public void onPartitionBecomeStandbyFromLeader(String partitionName) {
         //no op
       }
-    }, new AmbryReplicaSyncUpManager(config));
+
+      @Override
+      public void onPartitionBecomeInactiveFromStandby(String partitionName) {
+        // no op
+      }
+    });
     StateModel stateModel;
     switch (config.clustermapStateModelDefinition) {
       case ClusterMapConfig.OLD_STATE_MODEL_DEF:
diff --git a/ambry-clustermap/src/test/java/com.github.ambry.clustermap/MockHelixParticipant.java b/ambry-clustermap/src/test/java/com.github.ambry.clustermap/MockHelixParticipant.java
index 69a1017fe..b589dc21d 100644
--- a/ambry-clustermap/src/test/java/com.github.ambry.clustermap/MockHelixParticipant.java
+++ b/ambry-clustermap/src/test/java/com.github.ambry.clustermap/MockHelixParticipant.java
@@ -21,15 +21,49 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
+import java.util.concurrent.CountDownLatch;
 import java.util.stream.Collectors;
+import org.mockito.Mockito;
+import org.mockito.stubbing.Answer;
+
+import static org.mockito.Mockito.*;
 
 
 public class MockHelixParticipant extends HelixParticipant {
-  Set<ReplicaId> sealedReplicas = new HashSet<>();
-  Set<ReplicaId> stoppedReplicas = new HashSet<>();
+  CountDownLatch listenerLatch = null;
+  ReplicaState replicaState = ReplicaState.OFFLINE;
+  ReplicaId currentReplica = null;
+  ReplicaSyncUpManager replicaSyncUpService = null;
+  private Set<ReplicaId> sealedReplicas = new HashSet<>();
+  private Set<ReplicaId> stoppedReplicas = new HashSet<>();
+  private PartitionStateChangeListener mockReplicationManagerListener;
 
   public MockHelixParticipant(ClusterMapConfig clusterMapConfig) throws IOException {
     super(clusterMapConfig, new MockHelixManagerFactory());
+    // create mock state change listener for ReplicationManager
+    mockReplicationManagerListener = Mockito.mock(PartitionStateChangeListener.class);
+    // mock Bootstrap-To-Standby change
+    doAnswer((Answer) invocation -> {
+      replicaState = ReplicaState.BOOTSTRAP;
+      if (replicaSyncUpService != null && currentReplica != null) {
+        replicaSyncUpService.initiateBootstrap(currentReplica);
+      }
+      if (listenerLatch != null) {
+        listenerLatch.countDown();
+      }
+      return null;
+    }).when(mockReplicationManagerListener).onPartitionBecomeStandbyFromBootstrap(any(String.class));
+    // mock Standby-To-Inactive change
+    doAnswer((Answer) invocation -> {
+      replicaState = ReplicaState.INACTIVE;
+      if (replicaSyncUpService != null && currentReplica != null) {
+        replicaSyncUpService.initiateDeactivation(currentReplica);
+      }
+      if (listenerLatch != null) {
+        listenerLatch.countDown();
+      }
+      return null;
+    }).when(mockReplicationManagerListener).onPartitionBecomeInactiveFromStandby(any(String.class));
   }
 
   @Override
@@ -78,4 +112,13 @@ public void close() {
   public Map<StateModelListenerType, PartitionStateChangeListener> getPartitionStateChangeListeners() {
     return Collections.unmodifiableMap(partitionStateChangeListeners);
   }
+
+  /**
+   * Re-register state change listeners in {@link HelixParticipant} to replace original one with mock state change
+   * listener. This is to help with special test cases.
+   */
+  void registerMockStateChangeListeners() {
+    registerPartitionStateChangeListener(StateModelListenerType.ReplicationManagerListener,
+        mockReplicationManagerListener);
+  }
 }
diff --git a/ambry-replication/src/main/java/com.github.ambry.replication/CloudToStoreReplicationManager.java b/ambry-replication/src/main/java/com.github.ambry.replication/CloudToStoreReplicationManager.java
index edd552973..968f77c6f 100644
--- a/ambry-replication/src/main/java/com.github.ambry.replication/CloudToStoreReplicationManager.java
+++ b/ambry-replication/src/main/java/com.github.ambry.replication/CloudToStoreReplicationManager.java
@@ -65,7 +65,6 @@
 public class CloudToStoreReplicationManager extends ReplicationEngine {
   private final ClusterMapConfig clusterMapConfig;
   private final StoreConfig storeConfig;
-  private final StoreManager storeManager;
   private final ClusterSpectator vcrClusterSpectator;
   private final ClusterParticipant clusterParticipant;
   private static final String cloudReplicaTokenFileName = "cloudReplicaTokens";
@@ -101,10 +100,9 @@ public CloudToStoreReplicationManager(ReplicationConfig replicationConfig, Clust
       ClusterSpectator vcrClusterSpectator, ClusterParticipant clusterParticipant) throws ReplicationException {
     super(replicationConfig, clusterMapConfig, storeKeyFactory, clusterMap, scheduler, currentNode,
         Collections.emptyList(), connectionPool, metricRegistry, requestNotification, storeKeyConverterFactory,
-        transformerClassName, clusterParticipant);
+        transformerClassName, clusterParticipant, storeManager);
     this.clusterMapConfig = clusterMapConfig;
     this.storeConfig = storeConfig;
-    this.storeManager = storeManager;
     this.vcrClusterSpectator = vcrClusterSpectator;
     this.clusterParticipant = clusterParticipant;
     this.instanceNameToCloudDataNode = new AtomicReference<>(new ConcurrentHashMap<>());
@@ -375,6 +373,12 @@ public void onPartitionBecomeStandbyFromLeader(String partitionName) {
       }
     }
 
+    @Override
+    public void onPartitionBecomeInactiveFromStandby(String partitionName) {
+      logger.info("Partition state change notification from Standby to Inactive received for partition {}",
+          partitionName);
+    }
+
     /**
      * If only config specified list of partitions are being replicated from cloud, then check that the partition
      * belongs to the specified list.
diff --git a/ambry-replication/src/main/java/com.github.ambry.replication/ReplicaThread.java b/ambry-replication/src/main/java/com.github.ambry.replication/ReplicaThread.java
index 390cc2110..62741312a 100644
--- a/ambry-replication/src/main/java/com.github.ambry.replication/ReplicaThread.java
+++ b/ambry-replication/src/main/java/com.github.ambry.replication/ReplicaThread.java
@@ -448,12 +448,12 @@ public void replicate() {
                 ReplicaId remoteReplica = remoteReplicaInfo.getReplicaId();
                 boolean updated = replicaSyncUpManager.updateLagBetweenReplicas(localReplica, remoteReplica,
                     exchangeMetadataResponse.localLagFromRemoteInBytes);
-                // if updated is false, it means local replica is not found in replicaSyncUpManager and is therefore in
-                // bootstrap state
+                // if updated is false, it means local replica is not found in replicaSyncUpManager and is therefore not
+                // in bootstrap state.
                 if (updated && replicaSyncUpManager.isSyncUpComplete(localReplica)) {
                   // complete BOOTSTRAP -> STANDBY transition
                   remoteReplicaInfo.getLocalStore().setCurrentState(ReplicaState.STANDBY);
-                  replicaSyncUpManager.onBootstrapComplete(localReplica.getPartitionId().toPathString());
+                  replicaSyncUpManager.onBootstrapComplete(localReplica);
                   remoteReplicaInfo.getLocalStore().completeBootstrap();
                 }
               }
diff --git a/ambry-replication/src/main/java/com.github.ambry.replication/ReplicationEngine.java b/ambry-replication/src/main/java/com.github.ambry.replication/ReplicationEngine.java
index e5408b2e5..d7347e02d 100644
--- a/ambry-replication/src/main/java/com.github.ambry.replication/ReplicationEngine.java
+++ b/ambry-replication/src/main/java/com.github.ambry.replication/ReplicationEngine.java
@@ -20,12 +20,16 @@
 import com.github.ambry.clustermap.DataNodeId;
 import com.github.ambry.clustermap.PartitionId;
 import com.github.ambry.clustermap.ReplicaId;
+import com.github.ambry.clustermap.ReplicaState;
 import com.github.ambry.clustermap.ReplicaSyncUpManager;
 import com.github.ambry.commons.ResponseHandler;
 import com.github.ambry.config.ClusterMapConfig;
 import com.github.ambry.config.ReplicationConfig;
 import com.github.ambry.network.ConnectionPool;
 import com.github.ambry.notification.NotificationSystem;
+import com.github.ambry.server.StoreManager;
+import com.github.ambry.store.Store;
+import com.github.ambry.store.StoreException;
 import com.github.ambry.store.StoreKeyConverter;
 import com.github.ambry.store.StoreKeyConverterFactory;
 import com.github.ambry.store.StoreKeyFactory;
@@ -77,6 +81,7 @@
   protected final Map<PartitionId, PartitionInfo> partitionToPartitionInfo;
   protected final Map<String, Set<PartitionInfo>> mountPathToPartitionInfos;
   protected final ReplicaSyncUpManager replicaSyncUpManager;
+  protected final StoreManager storeManager;
   protected ReplicaTokenPersistor persistor = null;
 
   protected static final short Replication_Delay_Multiplier = 5;
@@ -86,7 +91,8 @@ public ReplicationEngine(ReplicationConfig replicationConfig, ClusterMapConfig c
       StoreKeyFactory storeKeyFactory, ClusterMap clusterMap, ScheduledExecutorService scheduler, DataNodeId dataNode,
       List<? extends ReplicaId> replicaIds, ConnectionPool connectionPool, MetricRegistry metricRegistry,
       NotificationSystem requestNotification, StoreKeyConverterFactory storeKeyConverterFactory,
-      String transformerClassName, ClusterParticipant clusterParticipant) throws ReplicationException {
+      String transformerClassName, ClusterParticipant clusterParticipant, StoreManager storeManager)
+      throws ReplicationException {
     this.replicationConfig = replicationConfig;
     this.storeKeyFactory = storeKeyFactory;
     try {
@@ -111,6 +117,7 @@ public ReplicationEngine(ReplicationConfig replicationConfig, ClusterMapConfig c
     this.sslEnabledDatacenters = Utils.splitString(clusterMapConfig.clusterMapSslEnabledDatacenters, ",");
     this.storeKeyConverterFactory = storeKeyConverterFactory;
     this.transformerClassName = transformerClassName;
+    this.storeManager = storeManager;
     replicaSyncUpManager = clusterParticipant == null ? null : clusterParticipant.getReplicaSyncUpManager();
   }
 
@@ -138,10 +145,35 @@ public boolean controlReplicationForPartitions(Collection<PartitionId> ids, List
 
   @Override
   public void updateTotalBytesReadByRemoteReplica(PartitionId partitionId, String hostName, String replicaPath,
-      long totalBytesRead) {
+      long totalBytesRead) throws StoreException {
     RemoteReplicaInfo remoteReplicaInfo = getRemoteReplicaInfo(partitionId, hostName, replicaPath);
     if (remoteReplicaInfo != null) {
+      ReplicaId localReplica = remoteReplicaInfo.getLocalReplicaId();
       remoteReplicaInfo.setTotalBytesReadFromLocalStore(totalBytesRead);
+      // update replication lag in ReplicaSyncUpManager
+      if (replicaSyncUpManager != null) {
+        Store localStore = storeManager.getStore(partitionId);
+        if (localStore.getCurrentState() == ReplicaState.INACTIVE) {
+          // if local store is in INACTIVE state, that means deactivation process is initiated and in progress on this
+          // replica. We update SyncUpManager by peer's lag from last PUT offset in local store.
+          // it's ok if deactivation has completed and subsequent metadata request attempts to update lag of same replica
+          // again. The reason is, in previous request, onDeactivationComplete method should have removed local replica
+          // from SyncUpManager and it should be no-op and "updated" should be false when calling updateLagBetweenReplicas()
+          // for subsequent request. Hence, it won't call onDeactivationComplete() twice.
+          boolean updated =
+              replicaSyncUpManager.updateLagBetweenReplicas(localReplica, remoteReplicaInfo.getReplicaId(),
+                  localStore.getEndPositionOfLastPut() - totalBytesRead);
+          // if updated = false, it means the replica is not present in SyncUpManager and therefore doesn't need to
+          // complete transition. We don't throw exception here because Standby-To-Inactive transition may already be
+          // complete but local store's state is still INACTIVE since it will be updated at the beginning of
+          // Inactive-To-Offline transition.
+          if (updated && replicaSyncUpManager.isSyncUpComplete(localReplica)) {
+            replicaSyncUpManager.onDeactivationComplete(localReplica);
+          }
+        }
+        // TODO, if local state == OFFLINE, it means replica might be in Inactive-To-Offline transition.
+        //  We need to update lag in replicaSyncUpManager accordingly as well.
+      }
     }
   }
 
diff --git a/ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java b/ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java
index fea24fdff..626d6dafc 100644
--- a/ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java
+++ b/ambry-replication/src/main/java/com.github.ambry.replication/ReplicationManager.java
@@ -41,12 +41,13 @@
 import java.util.concurrent.ScheduledExecutorService;
 import java.util.concurrent.TimeUnit;
 
+import static com.github.ambry.clustermap.StateTransitionException.TransitionErrorCode.*;
+
 
 /**
  * Set up replicas based on {@link ReplicationEngine} and do replication across all data centers.
  */
 public class ReplicationManager extends ReplicationEngine {
-  private final StoreManager storeManager;
   private final StoreConfig storeConfig;
 
   public ReplicationManager(ReplicationConfig replicationConfig, ClusterMapConfig clusterMapConfig,
@@ -57,8 +58,7 @@ public ReplicationManager(ReplicationConfig replicationConfig, ClusterMapConfig
       ClusterParticipant clusterParticipant) throws ReplicationException {
     super(replicationConfig, clusterMapConfig, storeKeyFactory, clusterMap, scheduler, dataNode,
         clusterMap.getReplicaIds(dataNode), connectionPool, metricRegistry, requestNotification,
-        storeKeyConverterFactory, transformerClassName, clusterParticipant);
-    this.storeManager = storeManager;
+        storeKeyConverterFactory, transformerClassName, clusterParticipant, storeManager);
     this.storeConfig = storeConfig;
     List<? extends ReplicaId> replicaIds = clusterMap.getReplicaIds(dataNode);
     // initialize all partitions
@@ -216,7 +216,7 @@ private void updatePartitionInfoMaps(List<RemoteReplicaInfo> remoteReplicaInfos,
   /**
    * {@link PartitionStateChangeListener} to capture changes in partition state.
    */
-  private class PartitionStateChangeListenerImpl implements PartitionStateChangeListener {
+  class PartitionStateChangeListenerImpl implements PartitionStateChangeListener {
 
     @Override
     public void onPartitionBecomeBootstrapFromOffline(String partitionName) {
@@ -226,7 +226,7 @@ public void onPartitionBecomeBootstrapFromOffline(String partitionName) {
         // no matter this is an existing replica or new added one, it should be present in storage manager because new
         // replica is added into storage manager first.
         throw new StateTransitionException("Replica " + partitionName + " is not found on current node",
-            StateTransitionException.TransitionErrorCode.ReplicaNotFound);
+            ReplicaNotFound);
       }
 
       if (!partitionToPartitionInfo.containsKey(replica.getPartitionId())) {
@@ -235,7 +235,7 @@ public void onPartitionBecomeBootstrapFromOffline(String partitionName) {
         logger.info("Didn't find replica {} in replication manager, starting to add it.", partitionName);
         if (!addReplica(replica)) {
           throw new StateTransitionException("Failed to add new replica " + partitionName + " into replication manager",
-              StateTransitionException.TransitionErrorCode.ReplicaOperationFailure);
+              ReplicaOperationFailure);
         }
       }
     }
@@ -248,8 +248,8 @@ public void onPartitionBecomeStandbyFromBootstrap(String partitionName) {
       Store store = storeManager.getStore(localReplica.getPartitionId());
       // 1. check if store is started
       if (store == null) {
-        throw new StateTransitionException("Store " + partitionName + " is not started",
-            StateTransitionException.TransitionErrorCode.StoreNotStarted);
+        throw new StateTransitionException(
+            "Store " + partitionName + " is not started during Bootstrap-To-Standby transition", StoreNotStarted);
       }
       // 2. check if store is new added and needs to catch up with peer replicas.
       if (store.isBootstrapInProgress()) {
@@ -273,5 +273,17 @@ public void onPartitionBecomeStandbyFromLeader(String partitionName) {
       logger.info("Partition state change notification from Leader to Standby received for partition {}",
           partitionName);
     }
+
+    @Override
+    public void onPartitionBecomeInactiveFromStandby(String partitionName) {
+      ReplicaId localReplica = storeManager.getReplica(partitionName);
+      Store store = storeManager.getStore(localReplica.getPartitionId());
+      // 1. check if store is started
+      if (store == null) {
+        throw new StateTransitionException(
+            "Store " + partitionName + " is not started during Standby-To-Inactive transition", StoreNotStarted);
+      }
+      replicaSyncUpManager.initiateDeactivation(localReplica);
+    }
   }
 }
diff --git a/ambry-replication/src/test/java/com.github.ambry.replication/InMemoryStore.java b/ambry-replication/src/test/java/com.github.ambry.replication/InMemoryStore.java
index da832ca62..25ca5d4f8 100644
--- a/ambry-replication/src/test/java/com.github.ambry.replication/InMemoryStore.java
+++ b/ambry-replication/src/test/java/com.github.ambry.replication/InMemoryStore.java
@@ -331,6 +331,11 @@ public ReplicaState getCurrentState() {
     return currentState;
   }
 
+  @Override
+  public long getEndPositionOfLastPut() throws StoreException {
+    throw new UnsupportedOperationException("Method not supported");
+  }
+
   @Override
   public void shutdown() throws StoreException {
     started = false;
diff --git a/ambry-replication/src/test/java/com.github.ambry.replication/MockReplicationManager.java b/ambry-replication/src/test/java/com.github.ambry.replication/MockReplicationManager.java
index 56c1d2ae9..c51d42cf1 100644
--- a/ambry-replication/src/test/java/com.github.ambry.replication/MockReplicationManager.java
+++ b/ambry-replication/src/test/java/com.github.ambry.replication/MockReplicationManager.java
@@ -31,6 +31,7 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
+import java.util.concurrent.CountDownLatch;
 
 
 /**
@@ -48,6 +49,8 @@
   // Variables for controlling getRemoteReplicaLagFromLocalInBytes()
   // the key is partitionId:hostname:replicaPath
   public Map<String, Long> lagOverrides = null;
+  CountDownLatch listenerExecutionLatch = null;
+  MockReplicationListener replicationListener = new MockReplicationListener();
 
   /**
    * Static construction helper
@@ -163,4 +166,26 @@ private void failIfRequired() {
       throw exceptionToThrow;
     }
   }
+
+  /**
+   * A class extends implementation of {@link ReplicationManager.PartitionStateChangeListenerImpl} to help manipulate
+   * ordering of threads' execution.
+   */
+  private class MockReplicationListener extends ReplicationManager.PartitionStateChangeListenerImpl {
+    @Override
+    public void onPartitionBecomeStandbyFromBootstrap(String partitionName) {
+      super.onPartitionBecomeStandbyFromBootstrap(partitionName);
+      if (listenerExecutionLatch != null) {
+        listenerExecutionLatch.countDown();
+      }
+    }
+
+    @Override
+    public void onPartitionBecomeInactiveFromStandby(String partitionName) {
+      super.onPartitionBecomeInactiveFromStandby(partitionName);
+      if (listenerExecutionLatch != null) {
+        listenerExecutionLatch.countDown();
+      }
+    }
+  }
 }
diff --git a/ambry-replication/src/test/java/com.github.ambry.replication/ReplicationTest.java b/ambry-replication/src/test/java/com.github.ambry.replication/ReplicationTest.java
index f200e332f..12254c357 100644
--- a/ambry-replication/src/test/java/com.github.ambry.replication/ReplicationTest.java
+++ b/ambry-replication/src/test/java/com.github.ambry.replication/ReplicationTest.java
@@ -50,8 +50,11 @@
 import com.github.ambry.protocol.ReplicaMetadataResponse;
 import com.github.ambry.store.Message;
 import com.github.ambry.store.MessageInfo;
+import com.github.ambry.store.MockId;
+import com.github.ambry.store.MockMessageWriteSet;
 import com.github.ambry.store.MockStoreKeyConverterFactory;
 import com.github.ambry.store.StorageManager;
+import com.github.ambry.store.Store;
 import com.github.ambry.store.StoreKey;
 import com.github.ambry.store.StoreKeyConverter;
 import com.github.ambry.store.StoreKeyFactory;
@@ -64,6 +67,7 @@
 import com.github.ambry.utils.TestUtils;
 import com.github.ambry.utils.Time;
 import com.github.ambry.utils.Utils;
+import com.github.ambry.utils.UtilsTest;
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.util.ArrayList;
@@ -298,7 +302,7 @@ public void replicaFromOfflineToBootstrapTest() throws Exception {
             .containsKey(StateModelListenerType.ReplicationManagerListener));
     // 1. test partition not found case (should throw exception)
     try {
-      mockHelixParticipant.onPartitionBecomeBootstrapFromOffline("invalidPartition");
+      mockHelixParticipant.onPartitionBecomeBootstrapFromOffline("-1");
       fail("should fail because replica is not found");
     } catch (StateTransitionException e) {
       assertEquals("Transition error doesn't match", StateTransitionException.TransitionErrorCode.ReplicaNotFound,
@@ -355,6 +359,7 @@ public void replicaFromBootstrapToStandbyTest() throws Exception {
     storageManager.shutdownBlobStore(existingPartition);
     try {
       mockHelixParticipant.onPartitionBecomeStandbyFromBootstrap(existingPartition.toPathString());
+      fail("should fail because store is not started");
     } catch (StateTransitionException e) {
       assertEquals("Error code doesn't match", StateTransitionException.TransitionErrorCode.StoreNotStarted,
           e.getErrorCode());
@@ -363,10 +368,107 @@ public void replicaFromBootstrapToStandbyTest() throws Exception {
     // 3. create new replica and add it into storage manager, test replica that needs to initiate bootstrap
     ReplicaId newReplicaToAdd = getNewReplicaToAdd(clusterMap);
     assertTrue("Adding new replica to Storage Manager should succeed", storageManager.addBlobStore(newReplicaToAdd));
-    mockHelixParticipant.onPartitionBecomeStandbyFromBootstrap(newReplicaToAdd.getPartitionId().toPathString());
-    assertEquals("Replica should be in BOOTSTRAP state before catchup is complete", ReplicaState.BOOTSTRAP,
+    // override partition state change listener in ReplicationManager to help thread manipulation
+    mockHelixParticipant.registerPartitionStateChangeListener(StateModelListenerType.ReplicationManagerListener,
+        replicationManager.replicationListener);
+    CountDownLatch participantLatch = new CountDownLatch(1);
+    replicationManager.listenerExecutionLatch = new CountDownLatch(1);
+    // create a new thread and trigger BOOTSTRAP -> STANDBY transition
+    Utils.newThread(() -> {
+      mockHelixParticipant.onPartitionBecomeStandbyFromBootstrap(newReplicaToAdd.getPartitionId().toPathString());
+      participantLatch.countDown();
+    }, false).start();
+    assertTrue("Partition state change listener in ReplicationManager didn't get called within 1 sec",
+        replicationManager.listenerExecutionLatch.await(1, TimeUnit.SECONDS));
+    assertEquals("Replica should be in BOOTSTRAP state before bootstrap is complete", ReplicaState.BOOTSTRAP,
         storageManager.getStore(newReplicaToAdd.getPartitionId()).getCurrentState());
+    // make bootstrap succeed
+    mockHelixParticipant.getReplicaSyncUpManager().onBootstrapComplete(newReplicaToAdd);
+    assertTrue("Bootstrap-To-Standby transition didn't complete within 1 sec",
+        participantLatch.await(1, TimeUnit.SECONDS));
+    storageManager.shutdown();
+  }
+
+  /**
+   * Test STANDBY -> INACTIVE transition on existing replica (both success and failure cases)
+   */
+  @Test
+  public void replicaFromStandbyToInactiveTest() throws Exception {
+    MockClusterMap clusterMap = new MockClusterMap();
+    ClusterMapConfig clusterMapConfig = new ClusterMapConfig(verifiableProperties);
+    MockHelixParticipant mockHelixParticipant = new MockHelixParticipant(clusterMapConfig);
+    Pair<StorageManager, ReplicationManager> managers =
+        createStorageManagerAndReplicationManager(clusterMap, clusterMapConfig, mockHelixParticipant);
+    StorageManager storageManager = managers.getFirst();
+    MockReplicationManager replicationManager = (MockReplicationManager) managers.getSecond();
+    // get an existing partition to test both success and failure cases
+    PartitionId existingPartition = replicationManager.partitionToPartitionInfo.keySet().iterator().next();
+    storageManager.shutdownBlobStore(existingPartition);
+    try {
+      mockHelixParticipant.onPartitionBecomeInactiveFromStandby(existingPartition.toPathString());
+      fail("should fail because store is not started");
+    } catch (StateTransitionException e) {
+      assertEquals("Error code doesn't match", StateTransitionException.TransitionErrorCode.StoreNotStarted,
+          e.getErrorCode());
+    }
+    // restart the store and trigger Standby-To-Inactive transition again
+    storageManager.startBlobStore(existingPartition);
+
+    // write a blob with size = 100 into local store (end offset of last PUT = 100 + 18 = 118)
+    Store localStore = storageManager.getStore(existingPartition);
+    MockId id = new MockId(UtilsTest.getRandomString(10), Utils.getRandomShort(TestUtils.RANDOM),
+        Utils.getRandomShort(TestUtils.RANDOM));
+    long crc = (new Random()).nextLong();
+    long blobSize = 100;
+    MessageInfo info =
+        new MessageInfo(id, blobSize, false, false, Utils.Infinite_Time, crc, id.getAccountId(), id.getContainerId(),
+            Utils.Infinite_Time);
+    List<MessageInfo> infos = new ArrayList<>();
+    List<ByteBuffer> buffers = new ArrayList<>();
+    ByteBuffer buffer = ByteBuffer.wrap(TestUtils.getRandomBytes((int) blobSize));
+    infos.add(info);
+    buffers.add(buffer);
+    localStore.put(new MockMessageWriteSet(infos, buffers));
+    ReplicaId localReplica = storageManager.getReplica(existingPartition.toPathString());
+
+    // override partition state change listener in ReplicationManager to help thread manipulation
+    mockHelixParticipant.registerPartitionStateChangeListener(StateModelListenerType.ReplicationManagerListener,
+        replicationManager.replicationListener);
+    CountDownLatch participantLatch = new CountDownLatch(1);
+    replicationManager.listenerExecutionLatch = new CountDownLatch(1);
+    // create a new thread and trigger STANDBY -> INACTIVE transition
+    Utils.newThread(() -> {
+      mockHelixParticipant.onPartitionBecomeInactiveFromStandby(existingPartition.toPathString());
+      participantLatch.countDown();
+    }, false).start();
+    assertTrue("Partition state change listener didn't get called within 1 sec",
+        replicationManager.listenerExecutionLatch.await(1, TimeUnit.SECONDS));
+    assertEquals("Local store state should be INACTIVE", ReplicaState.INACTIVE,
+        storageManager.getStore(existingPartition).getCurrentState());
 
+    List<RemoteReplicaInfo> remoteReplicaInfos =
+        replicationManager.partitionToPartitionInfo.get(existingPartition).getRemoteReplicaInfos();
+    ReplicaId peerReplica1 = remoteReplicaInfos.get(0).getReplicaId();
+    // we purposely update lag to verify that local replica is present in ReplicaSyncUpManager.
+    assertTrue("Updating lag between local replica and peer replica should succeed",
+        mockHelixParticipant.getReplicaSyncUpManager().updateLagBetweenReplicas(localReplica, peerReplica1, 10L));
+    // pick another remote replica to update the replication lag
+    ReplicaId peerReplica2 = remoteReplicaInfos.get(1).getReplicaId();
+    replicationManager.updateTotalBytesReadByRemoteReplica(existingPartition,
+        peerReplica1.getDataNodeId().getHostname(), peerReplica1.getReplicaPath(), 118);
+    assertFalse("Sync up shouldn't complete because only one replica has caught up with local replica",
+        mockHelixParticipant.getReplicaSyncUpManager().isSyncUpComplete(localReplica));
+    // make second peer replica catch up with last PUT in local store
+    replicationManager.updateTotalBytesReadByRemoteReplica(existingPartition,
+        peerReplica2.getDataNodeId().getHostname(), peerReplica2.getReplicaPath(), 118);
+
+    assertTrue("Standby-To-Inactive transition didn't complete within 1 sec",
+        participantLatch.await(1, TimeUnit.SECONDS));
+
+    // we purposely update lag against local replica to verify local replica is no longer in ReplicaSyncUpManager because
+    // deactivation is complete and local replica should be removed from "replicaToLagInfos" map.
+    assertFalse("Sync up should complete (2 replicas have caught up), hence updated should be false",
+        mockHelixParticipant.getReplicaSyncUpManager().updateLagBetweenReplicas(localReplica, peerReplica2, 0L));
     storageManager.shutdown();
   }
 
@@ -1630,7 +1732,7 @@ private ReplicaId getNewReplicaToAdd(MockClusterMap clusterMap) {
     storeKeyConverterFactory.setConversionMap(new HashMap<>());
     StorageManager storageManager =
         new StorageManager(storeConfig, new DiskManagerConfig(verifiableProperties), Utils.newScheduler(1, true),
-            new MetricRegistry(), null, clusterMap, dataNodeId, null, null, new MockTime(), null);
+            new MetricRegistry(), null, clusterMap, dataNodeId, null, clusterParticipant, new MockTime(), null);
     storageManager.start();
     MockReplicationManager replicationManager =
         new MockReplicationManager(replicationConfig, clusterMapConfig, storeConfig, storageManager, clusterMap,
diff --git a/ambry-server/src/main/java/com.github.ambry.server/StatsManager.java b/ambry-server/src/main/java/com.github.ambry.server/StatsManager.java
index 89d86cf10..6b1024ca2 100644
--- a/ambry-server/src/main/java/com.github.ambry.server/StatsManager.java
+++ b/ambry-server/src/main/java/com.github.ambry.server/StatsManager.java
@@ -47,6 +47,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import static com.github.ambry.clustermap.StateTransitionException.TransitionErrorCode.*;
 import static com.github.ambry.utils.Utils.*;
 
 
@@ -380,15 +381,14 @@ public void onPartitionBecomeBootstrapFromOffline(String partitionName) {
         // no matter this is an existing replica or new added one, it should be present in storage manager because new
         // replica is added into storage manager first.
         throw new StateTransitionException("Replica " + partitionName + " is not found on current node",
-            StateTransitionException.TransitionErrorCode.ReplicaNotFound);
+            ReplicaNotFound);
       }
       if (!partitionToReplicaMap.containsKey(replica.getPartitionId())) {
         // if replica is not present in partitionToReplicaMap, it means this new replica was just added into storage
         // manager. Here we add it into stats manager accordingly.
         logger.info("Didn't find replica {} in stats manager, starting to add it.", partitionName);
         if (!addReplica(replica)) {
-          throw new StateTransitionException("Failed to add new replica into stats manager",
-              StateTransitionException.TransitionErrorCode.ReplicaOperationFailure);
+          throw new StateTransitionException("Failed to add new replica into stats manager", ReplicaOperationFailure);
         }
       }
     }
@@ -410,5 +410,11 @@ public void onPartitionBecomeStandbyFromLeader(String partitionName) {
       logger.info("Partition state change notification from Leader to Standby received for partition {}",
           partitionName);
     }
+
+    @Override
+    public void onPartitionBecomeInactiveFromStandby(String partitionName) {
+      logger.info("Partition state change notification from Standby to Inactive received for partition {}",
+          partitionName);
+    }
   }
 }
diff --git a/ambry-server/src/test/java/com.github.ambry.server/MockStorageManager.java b/ambry-server/src/test/java/com.github.ambry.server/MockStorageManager.java
index 0ad3ffca4..16b09966e 100644
--- a/ambry-server/src/test/java/com.github.ambry.server/MockStorageManager.java
+++ b/ambry-server/src/test/java/com.github.ambry.server/MockStorageManager.java
@@ -194,6 +194,11 @@ public boolean isStarted() {
       return started;
     }
 
+    @Override
+    public long getEndPositionOfLastPut() throws StoreException {
+      throw new UnsupportedOperationException("Method not supported");
+    }
+
     public void shutdown() throws StoreException {
       throwExceptionIfRequired();
       started = false;
diff --git a/ambry-server/src/test/java/com.github.ambry.server/StatsManagerTest.java b/ambry-server/src/test/java/com.github.ambry.server/StatsManagerTest.java
index beaa7aa3b..afaf499bf 100644
--- a/ambry-server/src/test/java/com.github.ambry.server/StatsManagerTest.java
+++ b/ambry-server/src/test/java/com.github.ambry.server/StatsManagerTest.java
@@ -690,6 +690,11 @@ public ReplicaState getCurrentState() {
       throw new IllegalStateException("Not implemented");
     }
 
+    @Override
+    public long getEndPositionOfLastPut() throws StoreException {
+      throw new IllegalStateException("Not implemented");
+    }
+
     @Override
     public void shutdown() throws StoreException {
       throw new IllegalStateException("Not implemented");
diff --git a/ambry-store/src/main/java/com.github.ambry.store/BlobStore.java b/ambry-store/src/main/java/com.github.ambry.store/BlobStore.java
index 1c94622e2..26e693d32 100644
--- a/ambry-store/src/main/java/com.github.ambry.store/BlobStore.java
+++ b/ambry-store/src/main/java/com.github.ambry.store/BlobStore.java
@@ -757,6 +757,7 @@ public void deleteStoreFiles() throws StoreException, IOException {
    * @return return absolute end position of last PUT in current store when this method is invoked.
    * @throws StoreException
    */
+  @Override
   public long getEndPositionOfLastPut() throws StoreException {
     return index.getAbsoluteEndPositionOfLastPut();
   }
diff --git a/ambry-store/src/main/java/com.github.ambry.store/StorageManager.java b/ambry-store/src/main/java/com.github.ambry.store/StorageManager.java
index 64ac23824..b29c1711e 100644
--- a/ambry-store/src/main/java/com.github.ambry.store/StorageManager.java
+++ b/ambry-store/src/main/java/com.github.ambry.store/StorageManager.java
@@ -22,6 +22,7 @@
 import com.github.ambry.clustermap.PartitionId;
 import com.github.ambry.clustermap.PartitionStateChangeListener;
 import com.github.ambry.clustermap.ReplicaId;
+import com.github.ambry.clustermap.ReplicaState;
 import com.github.ambry.clustermap.ReplicaStatusDelegate;
 import com.github.ambry.clustermap.StateModelListenerType;
 import com.github.ambry.clustermap.StateTransitionException;
@@ -42,6 +43,8 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import static com.github.ambry.clustermap.StateTransitionException.TransitionErrorCode.*;
+
 
 /**
  * The storage manager that handles all the stores on this node. The stores on each disk are handled by a
@@ -387,14 +390,13 @@ public void onPartitionBecomeBootstrapFromOffline(String partitionName) {
         if (replicaToAdd == null) {
           logger.error("No new replica found for partition {} in cluster map", partitionName);
           throw new StateTransitionException(
-              "New replica " + partitionName + " is not found in clustermap for " + currentNode,
-              StateTransitionException.TransitionErrorCode.ReplicaNotFound);
+              "New replica " + partitionName + " is not found in clustermap for " + currentNode, ReplicaNotFound);
         }
         // Attempt to add store into storage manager. If store already exists, fail adding store request.
         if (!addBlobStore(replicaToAdd)) {
           logger.error("Failed to add store {} into storage manager", partitionName);
           throw new StateTransitionException("Failed to add store " + partitionName + " into storage manager",
-              StateTransitionException.TransitionErrorCode.ReplicaOperationFailure);
+              ReplicaOperationFailure);
         }
         // TODO, update InstanceConfig in Helix
         // note that partitionNameToReplicaId should be updated if addBlobStore succeeds, so replicationManager should be
@@ -409,7 +411,7 @@ public void onPartitionBecomeBootstrapFromOffline(String partitionName) {
         if (getStore(replica.getPartitionId(), false) == null) {
           throw new StateTransitionException(
               "Store " + partitionName + " didn't start correctly, replica should be set to ERROR state",
-              StateTransitionException.TransitionErrorCode.StoreNotStarted);
+              StoreNotStarted);
         }
       }
     }
@@ -428,5 +430,35 @@ public void onPartitionBecomeLeaderFromStandby(String partitionName) {
     public void onPartitionBecomeStandbyFromLeader(String partitionName) {
       // no op
     }
+
+    @Override
+    public void onPartitionBecomeInactiveFromStandby(String partitionName) {
+      // check if partition exists on current node
+      ReplicaId replica = partitionNameToReplicaId.get(partitionName);
+      // if replica is null that means partition is not on current node (this shouldn't happen unless we use server admin
+      // tool to remove the store before initiating decommission on this partition). We throw exception in this case.
+      if (replica != null) {
+        Store localStore = getStore(replica.getPartitionId());
+        if (localStore != null) {
+          // 1. set state to INACTIVE
+          localStore.setCurrentState(ReplicaState.INACTIVE);
+          logger.info("Store {} is set to INACTIVE", partitionName);
+          // 2. disable compaction on this store
+          if (!controlCompactionForBlobStore(replica.getPartitionId(), false)) {
+            logger.error("Failed to disable compaction on store {}", partitionName);
+            // we set error code to ReplicaNotFound because that is the only reason why compaction may fail.
+            throw new StateTransitionException("Couldn't disable compaction on replica " + replica.getReplicaPath(),
+                ReplicaNotFound);
+          }
+          logger.info("Compaction is successfully disabled on store {}", partitionName);
+        } else {
+          // this may happen when the disk holding this store crashes (or store is stopped by server admin tool)
+          throw new StateTransitionException("Store " + partitionName + " is not started", StoreNotStarted);
+        }
+      } else {
+        throw new StateTransitionException("Replica " + partitionName + " is not found on current node",
+            ReplicaNotFound);
+      }
+    }
   }
 }
diff --git a/ambry-store/src/test/java/com.github.ambry.store/StorageManagerTest.java b/ambry-store/src/test/java/com.github.ambry.store/StorageManagerTest.java
index 18fa6a96c..4a018b8a3 100644
--- a/ambry-store/src/test/java/com.github.ambry.store/StorageManagerTest.java
+++ b/ambry-store/src/test/java/com.github.ambry.store/StorageManagerTest.java
@@ -28,6 +28,7 @@
 import com.github.ambry.clustermap.PartitionId;
 import com.github.ambry.clustermap.PartitionStateChangeListener;
 import com.github.ambry.clustermap.ReplicaId;
+import com.github.ambry.clustermap.ReplicaState;
 import com.github.ambry.clustermap.StateModelListenerType;
 import com.github.ambry.clustermap.StateTransitionException;
 import com.github.ambry.config.ClusterMapConfig;
@@ -300,6 +301,60 @@ public void replicaFromOfflineToBootstrapTest() throws Exception {
     shutdownAndAssertStoresInaccessible(storageManager, localReplicas);
   }
 
+  /**
+   * test both success and failure cases during STANDBY -> INACTIVE transition
+   */
+  @Test
+  public void replicaFromStandbyToInactiveTest() throws Exception {
+    generateConfigs(true);
+    MockDataNodeId localNode = clusterMap.getDataNodes().get(0);
+    List<ReplicaId> localReplicas = clusterMap.getReplicaIds(localNode);
+    MockClusterParticipant mockHelixParticipant = new MockClusterParticipant();
+    StorageManager storageManager = createStorageManager(localNode, metricRegistry, mockHelixParticipant);
+    storageManager.start();
+    // 1. get listeners from Helix participant and verify there is a storageManager listener.
+    Map<StateModelListenerType, PartitionStateChangeListener> listeners =
+        mockHelixParticipant.getPartitionStateChangeListeners();
+    assertTrue("Should contain storage manager listener",
+        listeners.containsKey(StateModelListenerType.StorageManagerListener));
+    // 2. not found replica should encounter exception
+    try {
+      mockHelixParticipant.onPartitionBecomeInactiveFromStandby("-1");
+      fail("should fail because replica is not found");
+    } catch (StateTransitionException e) {
+      assertEquals("Error code doesn't match", StateTransitionException.TransitionErrorCode.ReplicaNotFound,
+          e.getErrorCode());
+    }
+    // 3. store not started exception
+    ReplicaId localReplica = localReplicas.get(0);
+    storageManager.shutdownBlobStore(localReplica.getPartitionId());
+    try {
+      mockHelixParticipant.onPartitionBecomeInactiveFromStandby(localReplica.getPartitionId().toPathString());
+      fail("should fail because store is not started");
+    } catch (StateTransitionException e) {
+      assertEquals("Error code doesn't match", StateTransitionException.TransitionErrorCode.StoreNotStarted,
+          e.getErrorCode());
+    }
+    storageManager.startBlobStore(localReplica.getPartitionId());
+    // 4. success case
+    mockHelixParticipant.onPartitionBecomeInactiveFromStandby(localReplica.getPartitionId().toPathString());
+    assertEquals("local store state should be set to INACTIVE", ReplicaState.INACTIVE,
+        storageManager.getStore(localReplica.getPartitionId()).getCurrentState());
+    shutdownAndAssertStoresInaccessible(storageManager, localReplicas);
+
+    // 5. mock disable compaction failure
+    MockStorageManager mockStorageManager = new MockStorageManager(localNode, mockHelixParticipant);
+    mockStorageManager.start();
+    try {
+      mockHelixParticipant.onPartitionBecomeInactiveFromStandby(localReplica.getPartitionId().toPathString());
+    } catch (StateTransitionException e) {
+      assertEquals("Error code doesn't match", StateTransitionException.TransitionErrorCode.ReplicaNotFound,
+          e.getErrorCode());
+    } finally {
+      shutdownAndAssertStoresInaccessible(mockStorageManager, localReplicas);
+    }
+  }
+
   /**
    * Test start BlobStore with given {@link PartitionId}.
    */
@@ -828,7 +883,7 @@ public void unrecognizedDirsOnDiskTest() throws Exception {
    * Construct a {@link StorageManager} for the passed in set of replicas.
    * @param currentNode the list of replicas for the {@link StorageManager} to use.
    * @param metricRegistry the {@link MetricRegistry} instance to use to instantiate {@link StorageManager}
-   * @param clusterParticipant
+   * @param clusterParticipant the {@link ClusterParticipant} to use in storage manager
    * @return a started {@link StorageManager}
    * @throws StoreException
    */
@@ -1023,5 +1078,23 @@ public void close() {
       // no op
     }
   }
+
+  /**
+   * An extension of {@link StorageManager} to help mock failure case
+   */
+  private class MockStorageManager extends StorageManager {
+    boolean controlCompactionReturnVal = false;
+
+    MockStorageManager(DataNodeId currentNode, ClusterParticipant clusterParticipant) throws Exception {
+      super(storeConfig, diskManagerConfig, Utils.newScheduler(1, false), metricRegistry, new MockIdFactory(),
+          clusterMap, currentNode, new DummyMessageStoreHardDelete(), clusterParticipant, SystemTime.getInstance(),
+          new DummyMessageStoreRecovery());
+    }
+
+    @Override
+    public boolean controlCompactionForBlobStore(PartitionId id, boolean enabled) {
+      return controlCompactionReturnVal;
+    }
+  }
 }
 
diff --git a/build.gradle b/build.gradle
index 1e844bc9f..822cb928b 100644
--- a/build.gradle
+++ b/build.gradle
@@ -274,6 +274,7 @@ project(':ambry-replication') {
         testCompile project(':ambry-commons').sourceSets.test.output
         testCompile project(':ambry-messageformat').sourceSets.test.output
         testCompile project(':ambry-store').sourceSets.main.output
+        testCompile project(':ambry-store').sourceSets.test.output
     }
 }
 
